{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Doc2Vec.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "K4kjQexCtbsj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 86
        },
        "outputId": "0ed5ada0-f00a-49cf-b68a-c87f47d29004"
      },
      "source": [
        "import pandas as pd\n",
        "import nltk\n",
        "import re\n",
        "import numpy as np\n",
        "nltk.download('punkt')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.svm import SVC, LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score,f1_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from gensim import utils\n",
        "from gensim.models.doc2vec import LabeledSentence,TaggedDocument\n",
        "from gensim.models import Doc2Vec\n",
        "import gensim"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cte1gPp4uHNH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 190
        },
        "outputId": "49a41d12-c1c8-4821-d144-e200fecf5cbb"
      },
      "source": [
        "df_train = pd.read_excel('P1_training.xlsx')\n",
        "df_test = pd.read_excel('P1_testing.xlsx')\n",
        "print(\"Training Data\")\n",
        "label=df_train['label']\n",
        "label_test=df_test['label']\n",
        "print(label.value_counts())\n",
        "print(\"Testing Data\")\n",
        "print(label_test.value_counts())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training Data\n",
            "1    736\n",
            "2    661\n",
            "0    263\n",
            "Name: label, dtype: int64\n",
            "Testing Data\n",
            "1    303\n",
            "2    298\n",
            "0     82\n",
            "Name: label, dtype: int64\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uKPpg-oYullQ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def preprocessor(text):\n",
        "  review=re.sub('\\[[^]]*\\]', ' ', text)\n",
        "  review=re.sub('[^a-zA-z]', ' ', text)\n",
        "  review=review.lower().split()\n",
        "  review=[i for i in review if not i in set(stopwords.words('english'))]\n",
        "  review= ' '.join(review)\n",
        "  return review\n",
        "df_train['sentence']=df_train['sentence'].apply(preprocessor)\n",
        "df_test['sentence']=df_test['sentence'].apply(preprocessor)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wk8-ecH4Z014",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentence=df_train['sentence']\n",
        "sentence_test=df_test['sentence']\n"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w8gRjyALTXuI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "81239fc3-dbb6-43a5-a202-707bc61296ce"
      },
      "source": [
        "temp_df=df_train\n",
        "lis=[i for i in range(0,1660)]\n",
        "temp_df['id']=lis\n",
        "temp_df"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>living concentration camp like atmosphere led ...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>even nod blues brothers believe filmmakers eve...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>park lord screenwriter karey kirkpatrick reali...</td>\n",
              "      <td>1</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ginger perfect spunky opinionated soft heart f...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>jane horrocks delivers lovely voice characteri...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1655</th>\n",
              "      <td>lin shae plays mary neighbor magda also appear...</td>\n",
              "      <td>2</td>\n",
              "      <td>1655</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1656</th>\n",
              "      <td>steve martin took extended vacation facets mov...</td>\n",
              "      <td>2</td>\n",
              "      <td>1656</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1657</th>\n",
              "      <td>much book spares tinseltown mockery although r...</td>\n",
              "      <td>2</td>\n",
              "      <td>1657</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1658</th>\n",
              "      <td>writer star bowfinger offers masses plenty goo...</td>\n",
              "      <td>1</td>\n",
              "      <td>1658</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1659</th>\n",
              "      <td>bowfinger latches onto idea immediately convin...</td>\n",
              "      <td>1</td>\n",
              "      <td>1659</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1660 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               sentence  label    id\n",
              "0     living concentration camp like atmosphere led ...      1     0\n",
              "1     even nod blues brothers believe filmmakers eve...      1     1\n",
              "2     park lord screenwriter karey kirkpatrick reali...      1     2\n",
              "3     ginger perfect spunky opinionated soft heart f...      2     3\n",
              "4     jane horrocks delivers lovely voice characteri...      2     4\n",
              "...                                                 ...    ...   ...\n",
              "1655  lin shae plays mary neighbor magda also appear...      2  1655\n",
              "1656  steve martin took extended vacation facets mov...      2  1656\n",
              "1657  much book spares tinseltown mockery although r...      2  1657\n",
              "1658  writer star bowfinger offers masses plenty goo...      1  1658\n",
              "1659  bowfinger latches onto idea immediately convin...      1  1659\n",
              "\n",
              "[1660 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qWZtCmPqWPsS",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 407
        },
        "outputId": "e5e0948d-1c06-4702-e356-26aeeda6bd5e"
      },
      "source": [
        "temp_df_test=df_test\n",
        "lis_test=[i for i in range(0,683)]\n",
        "temp_df_test['id']=lis_test\n",
        "temp_df_test"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sentence</th>\n",
              "      <th>label</th>\n",
              "      <th>id</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>even whole thing proves creative delusion one ...</td>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>quite sure handle sam deed starts explaining b...</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ruby close friend gretchen cuz ya love story w...</td>\n",
              "      <td>2</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>happy accidents romantic comedy filtered twelv...</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>film stars thandie newton robbed much deserved...</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>678</th>\n",
              "      <td>somehow considerable suspension disbelief larr...</td>\n",
              "      <td>1</td>\n",
              "      <td>678</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>679</th>\n",
              "      <td>occasionally violence slightly uncomfortable o...</td>\n",
              "      <td>0</td>\n",
              "      <td>679</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>680</th>\n",
              "      <td>perhaps sensational gods monsters brendan fras...</td>\n",
              "      <td>2</td>\n",
              "      <td>680</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>681</th>\n",
              "      <td>earned nomination touching performance althoug...</td>\n",
              "      <td>2</td>\n",
              "      <td>681</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>682</th>\n",
              "      <td>iron giant directed co written brad bird late ...</td>\n",
              "      <td>2</td>\n",
              "      <td>682</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>683 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                              sentence  label   id\n",
              "0    even whole thing proves creative delusion one ...      2    0\n",
              "1    quite sure handle sam deed starts explaining b...      1    1\n",
              "2    ruby close friend gretchen cuz ya love story w...      2    2\n",
              "3    happy accidents romantic comedy filtered twelv...      2    3\n",
              "4    film stars thandie newton robbed much deserved...      2    4\n",
              "..                                                 ...    ...  ...\n",
              "678  somehow considerable suspension disbelief larr...      1  678\n",
              "679  occasionally violence slightly uncomfortable o...      0  679\n",
              "680  perhaps sensational gods monsters brendan fras...      2  680\n",
              "681  earned nomination touching performance althoug...      2  681\n",
              "682  iron giant directed co written brad bird late ...      2  682\n",
              "\n",
              "[683 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LWsUwHL1ESh_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "texts = temp_df.to_dict('records') \n",
        "documents = [TaggedDocument(text['sentence'].split(), [text['id']])  for text in texts]   "
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-zON9is4aSx8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize\n",
        "res=[]\n",
        "for i in df_train['sentence']:\n",
        "  res.append(word_tokenize(i))\n",
        "\n",
        "res_test=[]\n",
        "for i in df_test['sentence']:\n",
        "  res_test.append(word_tokenize(i))"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-1gUSqYnIKaG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = gensim.models.Doc2Vec(vector_size=100,alpha=0.025,min_alpha=0.025, min_count=1, epochs=40)\n",
        "model.build_vocab(documents)\n",
        "model.train(documents, epochs=model.iter, total_examples=model.corpus_count)"
      ],
      "execution_count": 45,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OW2VJj4LJba1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "array=np.zeros((len(res),100))\n",
        "for i in range(len(df_train['sentence'])):\n",
        "  array[i,:]=model.docvecs[i].reshape((1,100))\n",
        "doc=pd.DataFrame(array)"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hb1Ww0cJRM-t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "array=np.zeros((len(res_test),100))\n",
        "for i in range(len(df_test['sentence'])):\n",
        "  array[i,:]=model.docvecs[i].reshape((1,100))\n",
        "doc_test=pd.DataFrame(array)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sMg4X4-jtk4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import warnings\n",
        "warnings. filterwarnings('ignore') "
      ],
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "noay4ynFVxIb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "134d660d-dc04-44a0-b140-c10a4db9919e"
      },
      "source": [
        "from sklearn.svm import SVC, LinearSVC\n",
        "clf=LinearSVC(max_iter=500)\n",
        "clf.fit(doc,label)\n",
        "predictions=clf.predict(doc_test)\n",
        "print (classification_report(label_test,predictions))\n",
        "print(\"Accuracy is\",accuracy_score(predictions,label_test))"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.09      0.01      0.02        82\n",
            "           1       0.47      0.54      0.50       303\n",
            "           2       0.47      0.51      0.49       298\n",
            "\n",
            "    accuracy                           0.46       683\n",
            "   macro avg       0.34      0.35      0.34       683\n",
            "weighted avg       0.42      0.46      0.44       683\n",
            "\n",
            "Accuracy is 0.46266471449487556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3mVJXOEuYuOh",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 207
        },
        "outputId": "920dd74f-71ab-435d-835f-5abf5e3ec3bd"
      },
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "clf=LogisticRegression(max_iter=100)\n",
        "clf.fit(doc,label)\n",
        "predictions=clf.predict(doc_test)\n",
        "print (classification_report(label_test,predictions))\n",
        "print(\"Accuracy is\",accuracy_score(predictions,label_test))"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00        82\n",
            "           1       0.47      0.55      0.51       303\n",
            "           2       0.47      0.49      0.48       298\n",
            "\n",
            "    accuracy                           0.46       683\n",
            "   macro avg       0.31      0.35      0.33       683\n",
            "weighted avg       0.41      0.46      0.43       683\n",
            "\n",
            "Accuracy is 0.45973645680819913\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}